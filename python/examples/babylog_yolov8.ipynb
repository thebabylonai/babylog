{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOV8 and how to log predictions using Babylog\n",
        "\n",
        "In this tutorial, we will learn the following:\n",
        "\n",
        "\n",
        "*   How to run inference with YOLOV8 on a single image\n",
        "*   How to log image and prediction data using [babylog](https://github.com/thebabylonai/babylog)\n",
        "* How to load the logged binaries and view the logged information\n"
      ],
      "metadata": {
        "id": "SIBws86yCcXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-requisites\n",
        "First, we will need to install `ultralytics` and `babylog`."
      ],
      "metadata": {
        "id": "aSpq20qXDul6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install babylog\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "MVYp_tpyCvUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running a YOLOV8 model on a sample image"
      ],
      "metadata": {
        "id": "vbYeraHKFKDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ultralytics.com/images/bus.jpg"
      ],
      "metadata": {
        "id": "JBCWekUYr_9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        " \n",
        "model = YOLO(\"yolov8n.pt\")  # loading a pretrained model, in this case the YOLOV8 nano model\n",
        "img = cv2.imread(\"bus.jpg\")"
      ],
      "metadata": {
        "id": "hdpGuGVYFZfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "times = []\n",
        "for i in range(20):\n",
        "  start_time = time.time()  # not using cuda time  measurement since inference is on cpu\n",
        "  results = model(img)\n",
        "  if i <= 3:  # discard first few measurements\n",
        "    times.append(time.time() - start_time)\n",
        "mean_latency = int(np.mean(times) * 1000)  # ms\n",
        "print('Avg execution time (ms): {}'.format(mean_latency))\n"
      ],
      "metadata": {
        "id": "nMfndOChv922"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boxes = results[0].boxes.numpy()  # Boxes object for bbox outputs\n",
        "boxes_xywh = boxes.xywh  # bounding boxes in x, y, width, height format\n",
        "cls = boxes.cls  # detected classes\n",
        "conf = boxes.conf # detection confidence"
      ],
      "metadata": {
        "id": "fBNrXLsPMA2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the bounding boxes to babylog's format\n",
        "boxes_babylog = [{'x': int(box[0]), \n",
        "                  'y': int(box[1]), \n",
        "                  'width': int(box[2]), \n",
        "                  'height': int(box[3]), \n",
        "                  'confidence': float(conf_),\n",
        "                  'classification': {model.names[int(cls_)]: 1.0}}\n",
        "                 for box, conf_, cls_ in zip(boxes_xywh, conf, cls)\n",
        "                 ]  "
      ],
      "metadata": {
        "id": "JcykDwI8Q0Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging CV inference using babylog"
      ],
      "metadata": {
        "id": "-47AFUHVOJSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/thebabylonai/babylog/master/python/resources/babylog.config.yaml"
      ],
      "metadata": {
        "id": "yZ7SoidEORfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from babylog import Babylog, VisionModelType, InferenceDevice\n",
        "\n",
        "bl = Babylog(\"babylog.config.yaml\")  # save_local is True by default\n",
        "\n",
        "bl.log(\n",
        "    image=img,\n",
        "    model_type=VisionModelType.DETECTION,\n",
        "    model_name=\"yolov8n_pretrained\",\n",
        "    model_version=\"0.0.1\",\n",
        "    latency=mean_latency,\n",
        "    inference_device=InferenceDevice.CPU,\n",
        "    detection=boxes_babylog,\n",
        ")\n",
        "\n",
        "bl.shutdown()"
      ],
      "metadata": {
        "id": "l2V2eR9aGpu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Viewing the logged information with babylog"
      ],
      "metadata": {
        "id": "vrRYYImhQJyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "logfile_path = glob.glob(\"./babylog/**/*.bin\", recursive=True)[0]"
      ],
      "metadata": {
        "id": "MY_qK1wYQbWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from babylog import LoggedPrediction\n",
        "\n",
        "logged_prediction = LoggedPrediction.from_path(logfile_path)  # from_path loads a prediction binary from path"
      ],
      "metadata": {
        "id": "nzgHkW_xQfD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_image = logged_prediction.image  # raw image that was logged"
      ],
      "metadata": {
        "id": "eNms8n9RllCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "for detection in logged_prediction.detection:\n",
        "  x = detection['x']; y = detection['y']; w = detection['width']; h = detection['height']\n",
        "  top_left = (x-w//2, y-h//2)\n",
        "  bottom_right = (x+w//2, y+h//2)\n",
        "\n",
        "  # visualizing the bounding boxes\n",
        "  color = (np.array([0., 0., 1.]) * 255).astype(np.uint8).tolist()\n",
        "  text = '{}:{:.1f}%'.format(detection['classificationResult'][0]['className'], detection['confidence'] * 100)\n",
        "  txt_color = (255, 255, 255)\n",
        "  font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "  txt_size = cv2.getTextSize(text, font, 0.8, 1)[0]\n",
        "\n",
        "  cv2.rectangle(predicted_image, top_left, bottom_right, color, 2)\n",
        "  txt_bk_color = (np.array([0.8, 0., 0.8]) * 255).astype(np.uint8).tolist()\n",
        "  cv2.rectangle(\n",
        "      predicted_image,\n",
        "      (top_left[0], top_left[1] + 1),\n",
        "      (top_left[0] + int(0.5*txt_size[0]) + 1, top_left[1] + int(1.5*txt_size[1])),\n",
        "      txt_bk_color,\n",
        "      -1\n",
        "  )\n",
        "  cv2.putText(predicted_image, text, (top_left[0], top_left[1] + txt_size[1]), font, 0.4, txt_color, thickness=1)"
      ],
      "metadata": {
        "id": "h-LsB_JbpjZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display inference stats\n",
        "device = logged_prediction.inference_stats['inferenceDevice']\n",
        "latency = logged_prediction.inference_stats['latency']\n",
        "stats = 'Inference stats: {}, {}ms'.format(device, latency)\n",
        "predicted_image = cv2.putText(predicted_image, stats, (50, 50), font, 1.0, (0., 255., 0.), thickness=2)\n",
        "\n",
        "# Display model info\n",
        "model_version = logged_prediction.model['version']\n",
        "model_name = logged_prediction.model['name']\n",
        "stats = 'Model info: {} v{}'.format(model_name, model_version)\n",
        "predicted_image = cv2.putText(predicted_image, stats, (50, 100), font, 1.0, (0., 255., 0.), thickness=2)\n"
      ],
      "metadata": {
        "id": "0PWR2hkb5zKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show image with inference result\n",
        "cv2_imshow(predicted_image)"
      ],
      "metadata": {
        "id": "nwfDD3JEyws1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}